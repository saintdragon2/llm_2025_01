from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations # (1) í•„ìš”í•œ í•¨ìˆ˜ ì„í¬íŠ¸
from openai import OpenAI
from dotenv import load_dotenv
import os
import json
import streamlit as st
from collections import defaultdict

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

client = OpenAI(api_key=api_key)  # OpenAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.


def tool_list_to_tool_obj(tools):
    # (1) ê¸°ë³¸ ê°’ì„ ê°€ì§„ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    tool_calls_dict = defaultdict(lambda: {"id": None, "function": {"arguments": "", "name": None}, "type": None})

    # (2) ë„êµ¬(í•¨ìˆ˜) í˜¸ì¶œì„ ë°˜ë³µí•˜ì—¬ ì²˜ë¦¬
    for tool_call in tools:
        # idê°€ Noneì´ ì•„ë‹Œ ê²½ìš° ì„¤ì •
        if tool_call.id is not None:
            tool_calls_dict[tool_call.index]["id"] = tool_call.id

        # í•¨ìˆ˜ ì´ë¦„ì´ Noneì´ ì•„ë‹Œ ê²½ìš° ì„¤ì •
        if tool_call.function.name is not None:
            tool_calls_dict[tool_call.index]["function"]["name"] = tool_call.function.name

        # ì¸ìˆ˜ ì¶”ê°€
        tool_calls_dict[tool_call.index]["function"]["arguments"] += tool_call.function.arguments

        # íƒ€ì…ì´ Noneì´ ì•„ë‹Œ ê²½ìš° ì„¤ì •
        if tool_call.type is not None:
            tool_calls_dict[tool_call.index]["type"] = tool_call.type

    # (3) ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    tool_calls_list = list(tool_calls_dict.values())

    return {"tool_calls": tool_calls_list}


def get_ai_response(messages, tools=None, stream=True):
    response = client.chat.completions.create(
        model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
        stream=stream, # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•´ ì„¤ì •
        messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
        tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
    )

    if stream: 
        for chunk in response:
            yield chunk  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ yieldë¡œ ìˆœì°¨ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    else:
        return response  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
st.title("ğŸ’¬ Chatbot")

# st.session_stateì— "messages"ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°ê°’ì„ ì„¤ì •í•œë‹¤. 
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
    ]

# ëŒ€í™” ê¸°ë¡ì„ ì¶œë ¥í•œë‹¤.
for msg in st.session_state.messages:
    if msg["role"] == "assistant" or msg["role"] == "user":
        st.chat_message(msg["role"]).write(msg["content"])

if user_input := st.chat_input():    
    st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    st.chat_message("user").write(user_input)

    ai_response = get_ai_response(st.session_state.messages, tools=tools)  # ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ AI ì‘ë‹µì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    # print(ai_response)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    content = ''
    tool_calls = None   # tool_calls ì´ˆê¸°í™”
    tool_calls_chunk = []   # tool_calls_chunk ì´ˆê¸°í™”

    with st.chat_message("assistant").empty(): # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±—ë©”ì‹œì§€ ì´ˆê¸°í™”
        for chunk in ai_response:
            content_chunk = chunk.choices[0].delta.content
            if content_chunk:
                print(content_chunk, end='')
                content += content_chunk
                st.markdown(content) # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±—ë©”ì‹œì§€ì— markdownìœ¼ë¡œ ì¶œë ¥
            
            # print(chunk) # ì„ì‹œë¡œ chunk ì¶œë ¥
            if chunk.choices[0].delta.tool_calls: # tool_callsê°€ ìˆëŠ” ê²½ìš°
                tool_calls_chunk += chunk.choices[0].delta.tool_calls # tool_calls_chunkì— ì¶”ê°€
        
        tool_obj = tool_list_to_tool_obj(tool_calls_chunk)
        tool_calls = tool_obj["tool_calls"]
 
        if len(tool_calls) > 0:
            print(tool_calls)
            tool_call_msg = [tool_call["function"] for tool_call in tool_calls]
            st.write(tool_call_msg)
        
    print('\n===========')
    print(content)
    
    if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
        for tool_call in tool_calls:
            # tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
            # tool_call_id = tool_call.id         # í•¨ìˆ˜ ì•„ì´ë”” ë°›ê¸°
            # arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
            
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—ì„œ ë°›ê¸°
            tool_name = tool_call["function"]["name"] 
            tool_call_id = tool_call["id"]         
            arguments = json.loads(tool_call["function"]["arguments"])
            
            if tool_name == "get_current_time":  # ë§Œì•½ tool_nameì´ "get_current_time"ì´ë¼ë©´
                func_result = get_current_time(timezone=arguments['timezone'])
                
            elif tool_name == "get_yf_stock_info":
                func_result = get_yf_stock_info(ticker=arguments['ticker'])

            elif tool_name == "get_yf_stock_history":  # (2) get_yf_stock_history í•¨ìˆ˜ í˜¸ì¶œ
                func_result = get_yf_stock_history(
                    ticker=arguments['ticker'], 
                    period=arguments['period']
                )
            
            elif tool_name == "get_yf_stock_recommendations":  # (3) get_yf_stock_recommendations í•¨ìˆ˜ í˜¸ì¶œ
                func_result = get_yf_stock_recommendations(
                    ticker=arguments['ticker']
                )
            
            st.session_state.messages.append({
                "role": "function",
                "tool_call_id": tool_call_id,
                "name": tool_name,
                "content": func_result,
            })

        ai_response = get_ai_response(st.session_state.messages)
        # ai_message = ai_response.choices[0].message
        content = ""
        with st.chat_message("assistant").empty():
            for chunk in ai_response:
                content_chunk = chunk.choices[0].delta.content
                if content_chunk:
                    print(content_chunk, end='')
                    content += content_chunk
                    st.markdown(content) # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±—ë©”ì‹œì§€ì— markdownìœ¼ë¡œ ì¶œë ¥

    st.session_state.messages.append({
        "role": "assistant",
        "content": content
    })  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.


    print("AI\t: " + content)  # AI ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.

